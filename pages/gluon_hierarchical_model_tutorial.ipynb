{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feeb5a18",
   "metadata": {},
   "source": [
    "# Hierarchical Model Tutorial\n",
    "\n",
    "\n",
    "This tutorial illustrates how to use GluonTS' deep-learning based hierarchical model\n",
    "`DeepVarHierarchical`. We first explain the data preparation for hierarchical/grouped time series,\n",
    "and then show the model training, prediction and evaluation using common use-cases.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The important aspect in using hierarchical models is the proper preparation of hierarchical\n",
    "time series data. The minimal requirements in building the hierarchical or grouped time series\n",
    "are the time series at the bottom-level of the hierarchy and the hierarchical/grouped\n",
    "aggregation matrix.\n",
    "`GluonTS` provides a simple way to construct hierarchical time series by reading the bottom-level\n",
    "time series and the aggregation matrix from csv files.\n",
    "Here we first describe the preparation of hierarchical time series before discussing the\n",
    "training of the hierarchical model.\n",
    "\n",
    "\n",
    "## Preparation of Hierarchical Time Series\n",
    "\n",
    "The bottom level time series are assumed to be available in a csv file as columns.\n",
    "The csv file should also contain the index column listing the time stamps for each row.\n",
    "Note that the aggregated time series are automatically constructed and should not be provided.\n",
    "Here is an [example csv](https://gist.githubusercontent.com/rshyamsundar/39e57075743537c4100a716a7b7ec047/raw/f02f5aeadad73e3f3e9cf54478606d3507826492/example_bottom_ts.csv) of bottom level time series.\n",
    "Similarly, the aggregation matrix can also be read from a csv file;\n",
    "here is an [example](https://gist.githubusercontent.com/rshyamsundar/17084fd1f28021867bcf6f2d69d9b73a/raw/32780ca43f57a78f2d521a75e73b136b17f34a02/example_agg_mat.csv).\n",
    "We use the standard format for the summation matrix;\n",
    "e.g., see Eq. 10.3 of the textbook [Forecasting: Principles and Practice](https://otexts.com/fpp2/hts.html).\n",
    "Note that grouped time series can also be represented by an aggregation matrix in the same\n",
    "way as the hierarchical time series and hence the material presented here is also applicable to\n",
    "grouped time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c2a977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:30:55.759416Z",
     "iopub.status.busy": "2024-05-31T18:30:55.759224Z",
     "iopub.status.idle": "2024-05-31T18:30:56.319307Z",
     "shell.execute_reply": "2024-05-31T18:30:56.318668Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gluonts.dataset.hierarchical import HierarchicalTimeSeries\n",
    "\n",
    "# Load (only!) the time series at the bottom level of the hierarchy.\n",
    "ts_at_bottom_level_csv = (\n",
    "    \"https://gist.githubusercontent.com/rshyamsundar/39e57075743537c4100a716a7b7ec047/\"\n",
    "    \"raw/f02f5aeadad73e3f3e9cf54478606d3507826492/example_bottom_ts.csv\"\n",
    ")\n",
    "\n",
    "# Make sure the dataframe has `PeriodIndex` by explicitly casting it to `PeriodIndex`.\n",
    "ts_at_bottom_level = pd.read_csv(\n",
    "    ts_at_bottom_level_csv,\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ").to_period()\n",
    "\n",
    "# Load the aggregation matrix `S`.\n",
    "S_csv = (\n",
    "    \"https://gist.githubusercontent.com/rshyamsundar/17084fd1f28021867bcf6f2d69d9b73a/raw/\"\n",
    "    \"32780ca43f57a78f2d521a75e73b136b17f34a02/example_agg_mat.csv\"\n",
    ")\n",
    "S = pd.read_csv(S_csv).values\n",
    "\n",
    "hts = HierarchicalTimeSeries(\n",
    "    ts_at_bottom_level=ts_at_bottom_level,\n",
    "    S=S,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f9894b",
   "metadata": {},
   "source": [
    "One can access all the time series of the hierarchy using `ts_at_all_levels` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5216b27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:30:56.322239Z",
     "iopub.status.busy": "2024-05-31T18:30:56.321817Z",
     "iopub.status.idle": "2024-05-31T18:30:56.334899Z",
     "shell.execute_reply": "2024-05-31T18:30:56.334230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-22 00:00</th>\n",
       "      <td>0.686671</td>\n",
       "      <td>0.156873</td>\n",
       "      <td>0.529798</td>\n",
       "      <td>0.056962</td>\n",
       "      <td>0.099911</td>\n",
       "      <td>0.039827</td>\n",
       "      <td>0.489971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-22 01:00</th>\n",
       "      <td>2.189128</td>\n",
       "      <td>0.669261</td>\n",
       "      <td>1.519866</td>\n",
       "      <td>0.246535</td>\n",
       "      <td>0.422727</td>\n",
       "      <td>0.763164</td>\n",
       "      <td>0.756702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-22 02:00</th>\n",
       "      <td>1.152853</td>\n",
       "      <td>0.582213</td>\n",
       "      <td>0.570640</td>\n",
       "      <td>0.314393</td>\n",
       "      <td>0.267820</td>\n",
       "      <td>0.169645</td>\n",
       "      <td>0.400996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-22 03:00</th>\n",
       "      <td>1.198889</td>\n",
       "      <td>0.653139</td>\n",
       "      <td>0.545750</td>\n",
       "      <td>0.609158</td>\n",
       "      <td>0.043981</td>\n",
       "      <td>0.235009</td>\n",
       "      <td>0.310741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-22 04:00</th>\n",
       "      <td>2.069197</td>\n",
       "      <td>0.678490</td>\n",
       "      <td>1.390707</td>\n",
       "      <td>0.380788</td>\n",
       "      <td>0.297702</td>\n",
       "      <td>0.898429</td>\n",
       "      <td>0.492278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0         1         2         3         4         5  \\\n",
       "2020-03-22 00:00  0.686671  0.156873  0.529798  0.056962  0.099911  0.039827   \n",
       "2020-03-22 01:00  2.189128  0.669261  1.519866  0.246535  0.422727  0.763164   \n",
       "2020-03-22 02:00  1.152853  0.582213  0.570640  0.314393  0.267820  0.169645   \n",
       "2020-03-22 03:00  1.198889  0.653139  0.545750  0.609158  0.043981  0.235009   \n",
       "2020-03-22 04:00  2.069197  0.678490  1.390707  0.380788  0.297702  0.898429   \n",
       "\n",
       "                         6  \n",
       "2020-03-22 00:00  0.489971  \n",
       "2020-03-22 01:00  0.756702  \n",
       "2020-03-22 02:00  0.400996  \n",
       "2020-03-22 03:00  0.310741  \n",
       "2020-03-22 04:00  0.492278  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hts.ts_at_all_levels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466dd689",
   "metadata": {},
   "source": [
    "## Model Training and Forecasting\n",
    "\n",
    "We now show the simplest use-case where we want to train the model on the whole dataset available\n",
    "and produce predictions for the future time steps.\n",
    "Note that this is how the model would be used in practice, once the best model\n",
    "has already been selected based on some user-specific evaluation criteria;\n",
    "see the next section for model evaluation.\n",
    "\n",
    "We assume that the hierarchical time series `hts` of type `HierarchicalTimeSeries` has already been\n",
    "constructed as described above.\n",
    "The first step is to convert this hierarchical time series to a `Dataset` on which\n",
    "mini-batch training can be run.\n",
    "Here we convert it into `gluonts.dataset.pandas.PandasDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10acc540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:30:56.337217Z",
     "iopub.status.busy": "2024-05-31T18:30:56.336834Z",
     "iopub.status.idle": "2024-05-31T18:30:56.341995Z",
     "shell.execute_reply": "2024-05-31T18:30:56.341313Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = hts.to_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186fc3cc",
   "metadata": {},
   "source": [
    "Once the dataset is created, it is straightforward to use the hierarchical model.\n",
    "Here, for a quick illustration, we fix the prediction length and choose a smaller number of epochs.\n",
    "We train on the whole dataset and give the same as the input to the trained model (called predictor) to\n",
    "generate predictions (or forecasts) for future/unseen time steps.\n",
    "The final output `forecasts` is an instance of `gluonts.model.forecast.SampleForecast`\n",
    "containing sample-based forecasts for all the time series in the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f928f002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:30:56.344329Z",
     "iopub.status.busy": "2024-05-31T18:30:56.343893Z",
     "iopub.status.idle": "2024-05-31T18:32:03.217821Z",
     "shell.execute_reply": "2024-05-31T18:32:03.217124Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [00:10<00:23,  1.49it/s, epoch=1/2, avg_epoch_loss=223]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 31/50 [00:20<00:12,  1.52it/s, epoch=1/2, avg_epoch_loss=193]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 47/50 [00:30<00:01,  1.53it/s, epoch=1/2, avg_epoch_loss=180]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:32<00:00,  1.53it/s, epoch=1/2, avg_epoch_loss=178]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [00:10<00:22,  1.54it/s, epoch=2/2, avg_epoch_loss=149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 32/50 [00:20<00:11,  1.53it/s, epoch=2/2, avg_epoch_loss=147]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 48/50 [00:31<00:01,  1.53it/s, epoch=2/2, avg_epoch_loss=146]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:32<00:00,  1.53it/s, epoch=2/2, avg_epoch_loss=146]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gluonts.mx.model.deepvar_hierarchical import DeepVARHierarchicalEstimator\n",
    "from gluonts.mx.trainer import Trainer\n",
    "\n",
    "prediction_length = 24\n",
    "estimator = DeepVARHierarchicalEstimator(\n",
    "    freq=hts.freq,\n",
    "    prediction_length=prediction_length,\n",
    "    trainer=Trainer(epochs=2),\n",
    "    S=S,\n",
    ")\n",
    "predictor = estimator.train(dataset)\n",
    "\n",
    "forecast_it = predictor.predict(dataset)\n",
    "\n",
    "# There is only one element in `forecast_it` containing forecasts for all the time series in the hierarchy.\n",
    "forecasts = next(forecast_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420304b",
   "metadata": {},
   "source": [
    "### Using external dynamic features\n",
    "\n",
    "By default, the hierarchical model `DeepVarHierarchical` internally creates several time-based/dynamic\n",
    "features for model training.\n",
    "These are seasonal features automatically deduced from the frequency of the target time series.\n",
    "One could also provide external dynamic features to the model if available.\n",
    "Here we show how this is done; we restart from the point where the hierarchical time series `hts` has\n",
    "already been created.\n",
    "\n",
    "We first load the available external features from a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add76894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:32:03.220857Z",
     "iopub.status.busy": "2024-05-31T18:32:03.220271Z",
     "iopub.status.idle": "2024-05-31T18:32:03.425386Z",
     "shell.execute_reply": "2024-05-31T18:32:03.424668Z"
    }
   },
   "outputs": [],
   "source": [
    "dynamic_features_csv = (\n",
    "    \"https://gist.githubusercontent.com/rshyamsundar/d8e63bad43397c95a4f5daaa17e122f8/\"\n",
    "    \"raw/a50657cf89f86d48cee41122f02cf5b1fcafdd2f/example_dynamic_features.csv\"\n",
    ")\n",
    "\n",
    "dynamic_features_df = pd.read_csv(\n",
    "    dynamic_features_csv,\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ").to_period()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d45734d",
   "metadata": {},
   "source": [
    "The dynamic features are assumed to be available both for the \"training range\"\n",
    "(time points where the target is available) as well as for the \"prediction range\"\n",
    "(future time points where the forecast is required).\n",
    "Thus, dynamic features are longer than the target time series by `prediction_length` time steps.\n",
    "\n",
    "For training the model, we need dynamic features only for the training range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3de1aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:32:03.428264Z",
     "iopub.status.busy": "2024-05-31T18:32:03.427856Z",
     "iopub.status.idle": "2024-05-31T18:32:03.431562Z",
     "shell.execute_reply": "2024-05-31T18:32:03.430840Z"
    }
   },
   "outputs": [],
   "source": [
    "dynamic_features_df_train = dynamic_features_df.iloc[:-prediction_length, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dcb958",
   "metadata": {},
   "source": [
    "We create the training dataset by passing the external features `dynamic_features_df_train`\n",
    "and train the model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb99f73b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:32:03.433974Z",
     "iopub.status.busy": "2024-05-31T18:32:03.433583Z",
     "iopub.status.idle": "2024-05-31T18:33:10.750615Z",
     "shell.execute_reply": "2024-05-31T18:33:10.749937Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [00:10<00:24,  1.45it/s, epoch=1/2, avg_epoch_loss=263]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 30/50 [00:20<00:13,  1.47it/s, epoch=1/2, avg_epoch_loss=216]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 46/50 [00:31<00:02,  1.49it/s, epoch=1/2, avg_epoch_loss=196]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:33<00:00,  1.48it/s, epoch=1/2, avg_epoch_loss=192]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [00:10<00:23,  1.50it/s, epoch=2/2, avg_epoch_loss=149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 30/50 [00:20<00:13,  1.50it/s, epoch=2/2, avg_epoch_loss=148]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [00:30<00:03,  1.49it/s, epoch=2/2, avg_epoch_loss=147]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:33<00:00,  1.49it/s, epoch=2/2, avg_epoch_loss=147]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_train = hts.to_dataset(feat_dynamic_real=dynamic_features_df_train)\n",
    "estimator = DeepVARHierarchicalEstimator(\n",
    "    freq=hts.freq,\n",
    "    prediction_length=prediction_length,\n",
    "    trainer=Trainer(epochs=2),\n",
    "    S=S,\n",
    ")\n",
    "predictor = estimator.train(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adbb659",
   "metadata": {},
   "source": [
    "To generate forecasts for future/unseen time steps, we need to pass both\n",
    "the past target (i.e., target in the training range) as well as\n",
    "full features `dynamic_features_df` (including those in the prediction range) to the trained model.\n",
    "Hence we need to create a new dataset that is separate from `dataset_train`,\n",
    "unlike in the earlier case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3b1abe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:33:10.753335Z",
     "iopub.status.busy": "2024-05-31T18:33:10.752949Z",
     "iopub.status.idle": "2024-05-31T18:33:10.933892Z",
     "shell.execute_reply": "2024-05-31T18:33:10.933197Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor_input = hts.to_dataset(feat_dynamic_real=dynamic_features_df)\n",
    "forecast_it = predictor.predict(predictor_input)\n",
    "\n",
    "# There is only one element in `forecast_it` containing forecasts for all the time series in the hierarchy.\n",
    "forecasts = next(forecast_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2dee75",
   "metadata": {},
   "source": [
    "## Model Evaluation via Backtesting\n",
    "\n",
    "We now explain how the hierarchical model can be evaluated via backtesting.\n",
    "For ease of presentation, we describe the model evaluation for the case where\n",
    "external dynamic features are available.\n",
    "However, it is straightforward to modify the code, in case external features are not\n",
    "available; simply invoke the function `to_dataset()` below without any arguments.\n",
    "\n",
    "We assume that time series at the bottom level `ts_at_bottom_level` and the\n",
    "aggregation matrix `S` have already been created as described above.\n",
    "We create the train-test split along the time axis by withholding the\n",
    "last `prediction_length` time points for evaluation and the remaining for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf5efa42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:33:10.936883Z",
     "iopub.status.busy": "2024-05-31T18:33:10.936468Z",
     "iopub.status.idle": "2024-05-31T18:33:10.969557Z",
     "shell.execute_reply": "2024-05-31T18:33:10.969038Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_length = 24\n",
    "hts_train = HierarchicalTimeSeries(\n",
    "    ts_at_bottom_level=ts_at_bottom_level.iloc[:-prediction_length, :],\n",
    "    S=S,\n",
    ")\n",
    "hts_test_label = HierarchicalTimeSeries(\n",
    "    ts_at_bottom_level=ts_at_bottom_level.iloc[-prediction_length:, :],\n",
    "    S=S,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc8e577",
   "metadata": {},
   "source": [
    "We load the external features as well and slice the features corresponding to the training range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "791b15fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:33:10.971793Z",
     "iopub.status.busy": "2024-05-31T18:33:10.971599Z",
     "iopub.status.idle": "2024-05-31T18:33:11.026214Z",
     "shell.execute_reply": "2024-05-31T18:33:11.025670Z"
    }
   },
   "outputs": [],
   "source": [
    "dynamic_features_csv = (\n",
    "    \"https://gist.githubusercontent.com/rshyamsundar/d8e63bad43397c95a4f5daaa17e122f8/\"\n",
    "    \"raw/a50657cf89f86d48cee41122f02cf5b1fcafdd2f/example_dynamic_features.csv\"\n",
    ")\n",
    "\n",
    "dynamic_features_df = pd.read_csv(\n",
    "    dynamic_features_csv,\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ").to_period()\n",
    "\n",
    "dynamic_features_df_train = dynamic_features_df.iloc[:-prediction_length, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b249310",
   "metadata": {},
   "source": [
    "We convert `hts_train` into `PandasDataset` by passing the external features `dynamic_features_df_train`\n",
    "and train the hierarchical model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69c39ed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:33:11.028642Z",
     "iopub.status.busy": "2024-05-31T18:33:11.028182Z",
     "iopub.status.idle": "2024-05-31T18:34:18.395369Z",
     "shell.execute_reply": "2024-05-31T18:34:18.394704Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [00:10<00:24,  1.45it/s, epoch=1/2, avg_epoch_loss=218]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 30/50 [00:20<00:13,  1.47it/s, epoch=1/2, avg_epoch_loss=191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [00:30<00:03,  1.48it/s, epoch=1/2, avg_epoch_loss=179]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:33<00:00,  1.48it/s, epoch=1/2, avg_epoch_loss=176]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [00:10<00:23,  1.49it/s, epoch=2/2, avg_epoch_loss=148]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 30/50 [00:20<00:13,  1.49it/s, epoch=2/2, avg_epoch_loss=146]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [00:30<00:03,  1.49it/s, epoch=2/2, avg_epoch_loss=145]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:33<00:00,  1.49it/s, epoch=2/2, avg_epoch_loss=144]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_train = hts_train.to_dataset(feat_dynamic_real=dynamic_features_df_train)\n",
    "\n",
    "estimator = DeepVARHierarchicalEstimator(\n",
    "    freq=hts.freq,\n",
    "    prediction_length=prediction_length,\n",
    "    trainer=Trainer(epochs=2),\n",
    "    S=S,\n",
    ")\n",
    "\n",
    "predictor = estimator.train(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877e7a15",
   "metadata": {},
   "source": [
    "To generate forecasts for time points corresponding to the\n",
    "withheld observations, we need to pass full features as well as the\n",
    "target in the training range to the trained model.\n",
    "So we create the input dataset for the predictor accordingly\n",
    "and generate forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8310f59b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:34:18.397898Z",
     "iopub.status.busy": "2024-05-31T18:34:18.397531Z",
     "iopub.status.idle": "2024-05-31T18:34:18.403828Z",
     "shell.execute_reply": "2024-05-31T18:34:18.403176Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor_input = hts_train.to_dataset(feat_dynamic_real=dynamic_features_df)\n",
    "forecast_it = predictor.predict(predictor_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f36150",
   "metadata": {},
   "source": [
    "Once the forecasts are obtained, we can evaluate them against the withheld observations.\n",
    "`GluonTS` evaluator takes as input an iterator over the true (withheld) observations and\n",
    "the corresponding forecasts to do the evaluation.\n",
    "Our forecasts are already in the correct format and our withheld observations are in\n",
    "`hts_test_label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a04f9f3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T18:34:18.406214Z",
     "iopub.status.busy": "2024-05-31T18:34:18.406011Z",
     "iopub.status.idle": "2024-05-31T18:34:18.662067Z",
     "shell.execute_reply": "2024-05-31T18:34:18.661337Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 1it [00:00, 145.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 1it [00:00, 154.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 1it [00:00, 156.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 1it [00:00, 157.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 1it [00:00, 163.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 1it [00:00, 140.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running evaluation: 1it [00:00, 164.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (weighted) quantile loss over all time series: 0.27951188855488635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:138: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    }
   ],
   "source": [
    "from gluonts.evaluation import MultivariateEvaluator\n",
    "\n",
    "evaluator = MultivariateEvaluator()\n",
    "agg_metrics, item_metrics = evaluator(\n",
    "    ts_iterator=[hts_test_label.ts_at_all_levels],\n",
    "    fcst_iterator=forecast_it,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Mean (weighted) quantile loss over all time series: \"\n",
    "    f\"{agg_metrics['mean_wQuantileLoss']}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
